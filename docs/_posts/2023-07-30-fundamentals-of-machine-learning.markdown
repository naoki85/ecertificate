---
layout: post
title:  "機械学習の基礎"
date:   2023-07-30 21:48:00 +0900
categories: machine-learning
---

# 機械学習の定義

[機械学習](https://ja.wikipedia.org/wiki/機械学習)  
Mitchell の提唱した定義が一般的だが、 Googfellow の定義も問題に出たりする。

# 尤度

想定するパラメーターがある値をとる場合に観測している事柄や事象が起こりうる確率のこと。  
尤度はパラメーターの関数として表すことができるので尤度関数とも言う。  
  
例えば、「2枚のコインを投げて2枚とも表が出た」という観測結果が得られた場合、この結果が観測される確率はコインが表になる確率 p をパラメーターとする関数 $$L(p) = p^2$$ で表すことができる。  
このとき、p = 0.2 であれば、尤度は0.04である。  
  
- [【統計学】尤度って何？をグラフィカルに説明してみる。 - Qiita](https://qiita.com/kenmatsu4/items/b28d1b3b3d291d0cc698)
- [尤度関数](https://ja.wikipedia.org/wiki/尤度関数)

# バイアス、バリアンス、ノイズ

- [バイアス・バリアンスとは?図解で分かりやすく数式まで徹底解説!! | 機械学習ナビ](https://nisshingeppo.com/ai/whats-bias-variance/)

一般的に、ニューラルネットワークはノイズに対して脆弱である。  
入力にノイズを加えて学習することは、理論的には「パラメータのノルムペナルティを課すこと」と等価である。

# サンプリング方法

ブートストラップ法は、元のデータセットからランダムに再サンプリングを行う統計的手法。  
この方法は、データの性質を理解するための代替的な手段を提供する。  
 具体的には、推定値の不確実性（標準誤差や信頼区間）を推定したり、モデルの精度を検証したりする。
例えば、ブートストラップサンプルを用いて複数のモデルを訓練し、それらのモデルの平均的なパフォーマンスを評価することで、モデルの精度を検証する。  
これはブートストラップ・アグリゲーティング（バギング）と呼ばれ、ランダムフォレストのようなアンサンブル学習手法の基礎となっています。

# 転移学習、ファインチューニング

既存の学習済みモデルを新しいタスクに適用するための手法。

## 転移学習

- 一つのタスク（ソースタスク）で学習した知識を別のタスク（ターゲットタスク）に適用する手法。
- 深層学習においては、一般的に大規模なデータセット（例：ImageNet）で事前に訓練されたモデル（例：VGG16、ResNet、BERT等）を使用する。
- この学習済みモデルの重みは、新しいタスクでのモデル訓練の初期値として使用される。
- このことにより、ターゲットタスクで必要となる訓練データの量を減らすとともに、モデルの汎化能力を向上させることが期待される。

例: 犬の画像判定ができるモデルを利用し、猫の画像が判定できるモデルに利用する。  
転移学習の多くでは、新しい層を追加した場合にはその層のみ再学習を行う。（ファインチューニング）

## ファインチューニング

**転移学習の一部** としてよく用いられる手法で、転移学習によって初期化されたモデルの重みをターゲットタスクに特化させるために微調整する。

- 一部または全ての層の重みをターゲットタスクのデータで再訓練し、モデルの性能を向上させる。
- ここで注意すべき点は、ファインチューニングにはターゲットタスクのデータが一定量必要であり、データが少なすぎると過学習（overfitting）のリスクがある。

要するに、転移学習は学習済みモデルを新しいタスクに適用する広範な概念であり、ファインチューニングはその中の一手法で、新しいタスクによりよく適合するようモデルを微調整するという点で両者は異なる。

# 性能評価

## ホールドアウト法

データを訓練データ、（検証データ、）テストデータに分割して学習、評価を行う手法。

## k-分割交差検証

データをk個の重複しない集合に分割し、そのうちの1つをテストデータ、残りを訓練データとして訓練、精度計算をおこない、これをk回繰り返して平均を取ることで精度評価を行う。特にデータセットの数が少ない場合に用いられる。