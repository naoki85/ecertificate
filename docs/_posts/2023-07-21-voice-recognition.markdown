---
layout: post
title:  "音声認識"
date:   2023-07-22 00:44:00 +0900
categories: voice-recognition
---

# CTC (Connectionist Temporal Classification)

- 音素を識別する際に、何もラベルをつけない「ブランク」を導入
- 出力データの系列長を入力データの系列長に合わせることで、異なる系列長の音声データの入出力での認識を可能にした

## 従来の手法との比較

従来の音声認識では音声を確率モデルで推定して表す隠れマルコフモデル（HMM）というモデルが主流となっていた。  
しかし、確率モデルを用いた推定であるがゆえに、音声を実際の時間長に合った認識しか行わないため精度が上がらなかった。  
  
それに対して、 CTC では音素を認識して配列を作っていく時に、何もないことを表す「ブランク」（ _ ）という記号を導入し、音声の長さに対して入力の音声と出力の音声をうまく対応づけられるようになった。  
確率分布モデルを使用せず、ニューラルネットワークだけで音声認識を実現できる。  

# WaveNet

WaveNet は、 Google の DeepMind によって開発された音声生成モデルで、畳み込みニューラルネットワーク（CNN）を使用して人間の声を非常にリアルに生成することができる。  
特に、音声合成（Text-to-Speech, TTS）システムで使用され、Googleの音声アシスタントで採用されている。  
  
特徴的な部分は、「希薄化したカジュアル畳み込み」（dilated causal convolutions）。  
これにより、畳み込み層は以前の層の出力を入力として受け取り、その出力を次の層に渡す。  
この形式は、「カジュアル」であるため、未来のデータが過去のデータに影響を与えることがないという時間系列データの特性を保持する。  
  
さらに、WaveNetは「希薄化した」畳み込みを使用している。  
これにより、ネットワークはより広範なコンテキストを捉えることができ、高品質な音声を生成することができる。  
この希薄化した畳み込みの効果は、ネットワークが深くなるにつれて、モデルが考慮する時間スケールが指数関数的に増加する。  
  
その結果、WaveNetは、人間の声のような複雑な音声パターンを学習し、非常にリアルな音声を生成することができる。  
また、異なる話者の声や、さまざまな音声スタイル（例えば、強調や感情）を模倣する能力も持っている。

# 高速フーリエ変換

高速フーリエ変換（Fast Fourier Transform, FFT）は、離散フーリエ変換（Discrete Fourier Transform, DFT）を高速に計算するためのアルゴリズムです。  
DFTは、離散的なデータを異なる周波数成分に分解することが可能な数学的手法で、信号処理や画像処理など、多くの分野で使われています。  
  
DFTの基本的な計算は、比較的シンプルですが、計算量が多くなる傾向があります。具体的には、N個のデータ点に対するDFTの計算は、通常O(N^2)の時間複雑度を持ちます。  
これに対して、高速フーリエ変換（FFT）は、DFTを効率的に計算するために開発されたアルゴリズムで、計算時間を大幅に削減できます。特に、Nが2のべき乗のとき、FFTはDFTをO(N log N)の時間で計算することが可能です。これは、大量のデータに対するフーリエ変換を実行する際に、非常に効率的です。  
  
FFTは、コムソル・コーリー演算（Cooley-Tukey algorithm）とも呼ばれるバタフライ演算を用いた再帰的な手法を用いています。この手法は、元のDFTをより小さいDFTに分解することにより、計算を高速化します。この性質により、FFTはデジタル信号処理、画像解析、音声解析、量子力学、経済学など、様々な分野で広く利用されています。  
  
例:  
複素数を関数に含まない音声の実信号の入力になるので、高速フーリエ変換で得られる周波数には対称的な折り返しが出ます。  
サンプリング周波数 16 kHz の信号に 1024 サンプルの窓をかけてフーリエ変換した場合を考えるときに得られる周波数スペクトル  
=> 0 Hz から 8 kHz までの、513 個の等分点における周波数情報が得られる

# メル尺度

メル尺度（Mel Scale）は、音声処理や音響学などの分野で使われる、人間の音の知覚を模倣した周波数尺度です。  
この尺度は、人間が音高（ピッチ）を感じる仕方を近似的に表現します。  
  
人間の耳は全ての周波数を等しく感じるわけではありません。  
特に、高い周波数領域では、実際の周波数の違いよりも、周波数の比（つまり、音程）を感じる傾向があります。  
メル尺度は、この感覚的な音高を量化します。
  
メル尺度は以下の公式で計算されます：  

$$
m = 2595 log_{10}(1 + f/700)
$$

ここで、`m`はメル値、`f`は周波数（Hz）です。この公式は、周波数が約1000Hz以下のときは、周波数とメル値がほぼ等しいという観測結果に基づいています。  
しかし、周波数が1000Hzを超えると、メル値は対数的に増加します。これは、人間の耳が高い周波数を感じる際の非線形性を反映しています。  
  
メル尺度は、音声処理の分野でよく用いられます。例えば、メル周波数ケプストラム係数（MFCC）は、スピーチ認識などのタスクで特徴量としてよく使われます。  
この計算では、まず信号のスペクトルをメル尺度に変換し、それに対して離散コサイン変換（DCT）を適用します。これにより、音声信号の感覚的な特性を反映した特徴量を得ることができます。

メル尺度は周波数パラメータによって決まる。  
[https://ja.wikipedia.org/wiki/%E3%83%A1%E3%83%AB%E5%B0%BA%E5%BA%A6](https://ja.wikipedia.org/wiki/%E3%83%A1%E3%83%AB%E5%B0%BA%E5%BA%A6)