---
layout: post
title:  "畳み込みニューラルネットワーク"
date:   2023-07-27 10:13:00 +0900
categories: cnn
---

# CNN

[https://xaqiita.com/obukoh/items/2916feae33c2f9ca193e](https://xaqiita.com/obukoh/items/2916feae33c2f9ca193e)

- 畳み込みにおいて、フィルタが大きくなると計算量は増大する。
- 畳み込みは、入力チャンネル数より出力のチャンネル数を大きくするもできる。
- 畳み込みにおけるフィルタサイズは、正方形だけではなく、長方形でも良い。
- 一般にプーリングには学習によって定めるパラメータは存在しない。
- 畳み込み層の後に必ずしもプーリング層を設ける必要はない。FCN や U-Net では、プーリングを利用しない。
- プーリングにおけるウィンドウのサイズは、偶数でも奇数でも問題ない。
- 通常、畳み込み層が持つ学習パラメータ数は、 $$c_{in}c_{out}f^2$$ となる。 c はチャンネル数。

# AlexNet と GoogleLeNet

## AlexNet

AlexNetは、2012年に開催された大規模な画像認識コンテスト（ImageNet Large Scale Visual Recognition Challenge、ILSVRC）で優勝したモデル。  
深層学習が大規模なデータセットで優れたパフォーマンスを達成できることを証明した。  

AlexNetは、畳み込み層、プーリング層、正規化層、全結合層からなる深いネットワークで、 **ReLU** という非線形活性化関数の使用、オーバーフィッティングを防ぐためのドロップアウトの使用など、現在の深層学習における標準的なテクニックを初めて広く使用した。  
プーリング層では、 **max プーリング** が使用されている。

## GoogLeNet

GoogLeNetは、2014年のILSVRCで優勝したモデルで、Googleの研究者たちによって開発された。  
GoogLeNetは、特にそのInceptionモジュールという概念で知られている。  
Inceptionモジュールは、ネットワークに様々なスケールの畳み込み操作を同時に行わせ、その結果を結合するというアイデアを導入した。  
これにより、ネットワークは異なるスケールの特徴を同時に学習できるようになった。  

Inceptionモジュールは他にも、以下の特徴がある。

- K×K の畳み込みフィルタと比較すると非零のパラメータが増えているとみなせるため、相対的に dense な演算であると言える。
- 大きな畳み込みフィルタを小さな畳み込みフィルタのグループで近似することで、モデルの表現力とパラメータ数のトレードオフを改善していると言える。
- 1×1の畳み込みフィルタが使われているが、このフィルタは次元削減と等価な効果がある。

  
GoogLeNetはまた、最後の全結合層を削除して、グローバル平均プーリング層を導入した。  
これによりモデルのパラメータ数が大幅に減少し、計算効率が向上した。

# ResNet と DenseNet

ResNetとDenseNetは、深層学習における主要なアーキテクチャであり、画像認識やセグメンテーションなどのタスクで高い精度を発揮している。

## ResNet

ResNetは、2015年にMicrosoft Researchが発表したニューラルネットワークのアーキテクチャで、非常に深いネットワークを効率的に学習することができる。  
VGG をベースに、スキップ接続を使用して、ネットワークが深くなるにつれて勾配消失問題を解決する。  

層をまたがる結合のことを Identity mapping という。

## WideResNet

ResNet の層の深さを浅くし、フィルタ数を増やしてネットワークの幅を広くすることで改良したモデル。

## DenseNet

DenseNet は、2017年に発表されたニューラルネットワークのアーキテクチャで、ResNetと同様に勾配消失問題を解決する。  
しかし、DenseNetは、各層が前の層の出力を直接受け取ることにより、ネットワークの特徴量をより効率的に再利用する。

- [代表的モデル「ResNet」、「DenseNet」を詳細解説！](https://deepsquare.jp/2020/04/resnet-densenet/)

## EfficientNet

このネットワークは、モデルのサイズ（幅、深さ、画像解像度）を調整する新しい方法。

# 物体検出

## R-CNN

- 領域提案（Region Proposal）: まず、画像内で興味深い領域を見つけ出すために、領域提案アルゴリズム（例えば **Selective Search** ）が使用される。このアルゴリズムは、潜在的に何千もの領域提案を生成する。
- 特徴抽出: 次に、各領域提案がCNNを通過し、それぞれの提案から特徴ベクトルが抽出される。これは領域提案がオブジェクトの一部を含んでいる場合に、その特徴を捉えるため。
- 分類: 最後に、特徴ベクトルが分類器（SVMなど）に供給され、個々の領域提案が特定のクラス（犬、猫、車など）に属するかどうかが決定される。また、境界ボックス回帰（Bounding Box Regression）が適用されて、オブジェクトの位置をより正確に予測する。

R-CNNは非常に正確である一方で、計算上非常に高コストなアルゴリズムであり、リアルタイムのオブジェクト検出には適していなかった。  
課題点としては、

- 候補領域ごとに畳み込みによる特徴抽出が必要
- 選択的探索による候補領域の決定に時間を要する

## Fast R-CNN

Fast R-CNNは、R-CNNの計算効率と速度を大幅に改善したもの。  
主な変更点は、

- 共有畳み込み: Fast R-CNNは、領域提案に対して個別に畳み込みを行うのではなく、画像全体を複数回畳み込んで特徴マップを生成し、得られた特徴マップから各候補領域に該当する部分を特定する。これにより計算コストが大幅に削減された。
- RoIプーリング（Region of Interest Pooling）: Fast R-CNNは畳み込み特徴マップからRoI（領域提案）を抽出し、それを固定サイズの特徴マップに変換します。これにより、異なるサイズとアスペクト比を持つ領域提案を一貫した方法で処理できる。
- 複数のタスクを一つのネットワークで行う: Fast R-CNNは、オブジェクト分類と境界ボックス回帰（オブジェクトの位置調整）の両方を一つのネットワークで行う。

## Faster R-CNN

Faster R-CNNは、Fast R-CNNをさらに改良したもので、オブジェクト検出の精度を保ちつつ計算効率を向上させた。  
主な改良点は、

- 領域提案ネットワーク（Region Proposal Network、RPN）: Faster R-CNNは領域提案を生成するために、別の手法（例えば、Selective Search）ではなく、学習可能なニューラルネットワークを使用する。
- RPNは、畳み込み特徴マップ上でスライドウィンドウを行い、各位置でオブジェクトの境界ボックスとそのオブジェクトネススコアを同時に予測する。
- スライディングウィンドウには、それぞれ異なるスケール、アスペクト比を持つアンカーボックスを設定しておく。
- アンカーボックスの個数は H * W * k となる。

## YOLO (You Only Look Once)

YOLO は、2016年に導入され、いくつかの改修がされてきた。  
YOLO は、ニューラルネットワークの単一の前方パスで画像内のオブジェクトを検出するリアルタイムオブジェクト検出システム。  
スライディングウィンドウアプローチを使用する従来の物体検出アルゴリズムに比べ、YOLO は画像全体を一度に処理するため、より高速に動作する。  
また、YOLO はアンカーボックスを使用してオブジェクトの位置とサイズを予測するため、精度が向上している。  
  
画像内のオブジェクト同士が複数重なっている場合にうまく検出できない。  
YOLOでは画像をある固定長で分解したセルごとにそれぞれどのカテゴリの物体なのかもしくはただの背景なのか、のそれぞれの確率が出力される。  
グリッド状に分割された画像を入力とし、グリッドの各セルごとに **バウンティングボックスとその信頼度の予測** と **クラスの分類** の2つのタスクを同時に学習し、既存の手法より高い精度で物体検出を実現している。  
non-maximum suppression という考え方で、スコアの低いものから除外していく。  
  
[【物体検出】 Non-Maximum Suppression (NMS)で余分なBounding Boxを削除する](https://note.com/kikaben/n/nf4ddafd80492)

## SSD (Single Shot Detector)

SSD は、2016年に同様に導入され、YOLO と同様にシングルショットの物体検出アルゴリズム。
しかし、SSD は、YOLO のようなアンカーボックスを使用する代わりに、 **デフォルトボックスのセットを使用して複数のスケールとアスペクト比** でオブジェクトの位置とサイズを予測している。

- [物体検出の５つの代表的なアーキテクチャの特徴まとめ](https://ai-kenkyujo.com/artificial-intelligence/ai-architecture/)  

YOLO や SSD に代表されるシングルショット系の手法では、グリッドごとに所定の数の物体を検出する。  
モデルの構造がシンプルなこと、軽量に動作すること、背景の特徴を暗に学習できるという特徴がある。

## FCOS (Fully Convolutional One-Stage Object Detection) 

物体検出タスクを行うためのOne-Stage（一段階）の畳み込みネットワーク。  
一般的な物体検出アルゴリズムは、物体の「候補」領域を生成し（これを「proposal generation」と呼びます）、次にこれらの領域を分類します。  
これは「Two-Stage」（二段階）のアプローチと呼ばれます。Faster R-CNN はこのアプローチの一例です。  
  
しかし、FCOSはこれとは異なり、proposal generationのステップを省きます。  
これは「One-Stage」（一段階）のアプローチと呼ばれ、物体検出の処理をより効率的にします。  
  
FCOSは、全畳み込みネットワーク（Fully Convolutional Network）を使用して、直接的に物体の位置とクラスを予測します。  
各位置において、ネットワークは物体の中心点であるかどうか、及びその物体のクラスとバウンディングボックスのサイズを予測します。  
  
また、FCOSはアンカーフリーな手法を採用しています。一般的なアンカーベースの手法（例：Faster R-CNN, YOLO, SSD）では、事前に定義された形状やサイズのアンカーボックス（物体の候補領域）を使用しますが、FCOSではこのアンカーボックスを必要としません。  
これにより、モデルの設計やトレーニングが簡素化され、さらに性能の改善が可能になります。  
これらの特性により、FCOSは高い精度と効率性を達成しており、物体検出の一般的な手法として幅広く使用されています。

# セマンティックセグメンテーション

セマンティックセグメンテーションでは、ピクセルごとに分類問題を解くため、いくつかのピクセルが孤立して異なるクラスに割り当てられてしまうことがある。  
この場合、 **条件付き確率場** による後処理を施すことで精度向上が期待できる。

## FCN (Fully Convolutional Network)

FCN は、画像セグメンテーションタスクで使用されるニューラルネットワークアーキテクチャの1つ。  
FCN 以前は、ネットワーク内に全結合層が存在するため、固定サイズの画像しか扱えなかった。  
FCNは、 **任意のサイズの画像を処理し** 、入力画像のピクセルごとの分類を出力する完全畳み込みニューラルネットワーク。  
FCNは、画像内のオブジェクトを識別し、各ピクセルに対応するオブジェクトクラスをラベル付けするなどのセマンティックセグメンテーションタスクに広く使用されている。  
  
FCNによる出力ユニット数は **画像サイズ×分類クラス数** になる。

## SegNet

SegNetは、画像セグメンテーションタスクに使用される別のニューラルネットワークアーキテクチャ。  
SegNetは、エンコーダとデコーダが畳み込みとプーリング層で構成された完全畳み込みエンコーダ・デコーダアーキテクチャに基づいている。  
エンコーダは、入力画像を低次元の特徴空間に圧縮し、デコーダは、圧縮された特徴をアップサンプリングして入力画像のセグメンテーションマップを生成する。  
SegNetは、セマンティックセグメンテーションや道路検出などのタスクに広く使用されている。

## U-Net

U-Netは、畳み込みニューラルネットワークアーキテクチャ。  
U-Netは、顕微鏡画像中の細胞核を識別するなどの生体医学画像セグメンテーションタスクに設計されている。  
U-Netは、入力画像のコンテキストをキャプチャして空間分解能を低下させる収縮路と、空間分解能を回復してセグメンテーションマップを生成する膨張路から構成されている。  
U-Netは、画像セグメンテーションやセマンティックセグメンテーションなどの様々なセグメンテーションタスクで広く使用されている。  
デコーダはエンコーダから渡された特徴マップをチャンネル方向に結合し、転置畳み込みで拡大する。
  
- [【セマンティックセグメンテーション手法】Segnetのネットワーク構造や性能をU-Netと比較](https://ys0510.hatenablog.com/entry/segnet)

## Mask R-CNN

物体検出とセグメンテーション（ピクセル単位での物体認識）を同時に行うための強力なフレームワークで、R-CNNの一種。
基本的にはFaster R-CNNと非常に似ているが、その上に追加の分岐を追加することでセグメンテーションを行う。  
モデルの出力部に物体検出機構と Mask 機構が並列に接続されている。このとき、 Mask R-CNN の物体検出精度は、 Mask R-CNN から Mask 機構を取り除いた場合と比較し、マルチタスク学習の寄与により精度が向上する。  
  
Mask 機構はピクセル単位でクラス分類を行うものであり、これにより Mask R-CNN は画像中の背景と各物体をピクセル単位で分類するインスタンスセグメンテーションが可能になりました。  
また、Mask R-CNN では、 RoIPool の代わりに **RoIAlign** という新しい方法が導入されている。  
RoIPool は、物体の位置を浮動小数点数から整数に変換するため、物体の位置情報が多少失われる。  
一方、RoIAlignではバイリニア補間を使用してピクセルレベルでの正確な位置情報を保持する。  
これにより、セグメンテーションの精度が向上する。

# 畳み込み手法

- グループ畳み込みは、複数のチャンネルを1つのグループとみなし、グループごとにチャンネル間の関係性を取ることで、チャンネル方向のパラメータ数を削減する軽量な畳み込み。
- デプスワイズ畳み込みは、チャンネルごとに畳み込みを行うものです。G=Cの制限がかかりますが、軽量な畳み込みを実現。パラメータ数が $$1/c_{out}$$ になる。
- ダイレイト畳み込みは、畳み込みにおけるフィルタの間隔を広げることで、小さな畳み込みフィルタで広い空間的受容野を実現する畳み込み。少ないパラメータ数で広範囲の畳み込みを実現する。
- ポイントワイズ畳み込みは、チャンネル方向のみの相関を取るフィルタサイズ 1×1 の畳み込み。1×1 畳み込みやカスケード・クロス・チャンネルプーリングと呼ばれることもある。チャンネル数の辻褄を合わせることができるため非常によく用いられる畳み込みである。パラメータ数が $$1/f^2$$ になる。
- 転置畳み込みは、生成モデルなどで小さな画像から大きな画像を生成する際に使用される。
