---
layout: post
title:  "深層学習の説明性"
date:   2023-07-23 23:38:00 +0900
categories: explainability-of-deep-learning
---

# SHAP (SHapley Additive exPlanations)

ある入力に対しての予測結果に対して、どの特徴量が寄与したのかを解析する手法。  
LIME と同様、局所的説明である。  

SHAP では入力 $$x = [x_1, x_2, ...x_m]^T$$ と学習されたモデル f が与えられた時、モデル f を各変数の寄与度が説明しやすい簡単なモデルで近似する。

$$
g(z') = \phi_0 + \sum_{j=1}^{M} \phi_j z_i'
z' = [z_1', ..., z_M']
$$

ここで、入力 xを単純化した z′ を考える。
各 $$z_i'$$ は例えば x の i 番目の変数が観測されていれば 1 、そうでなければ 0 となる。
今求めたい変数の寄与度は上式での $$\phi_i$$ 。  
  
SHAPではモデル g に対して次の性質を持つように制約を加えます。  
  
- local accuracy: 学習済みモデル f で予測した結果 f(x) とモデル g で予測した結果 g(z) が一致、つまり $$\phi_i$$ の和は説明したいモデルの出力値 f(x) に等しい。
- missingness: $$z_i' = 0$$ のときは $$\phi_i = 0$$ 。つまり、結果に影響を与えないような特徴量は、その予測に対して貢献していない。
- consistency: ある変数のモデル f の出力に対する影響力が大きければ、その変数の寄与は大きくなる（ $$\phi_i = 0$$ が大きくなる）