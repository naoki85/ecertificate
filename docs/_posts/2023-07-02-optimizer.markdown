---
layout: post
title:  "学習の最適化手法"
date:   2023-07-02 10:13:00 +0900
categories: optimizer
---

# Optimizer

## Adam

Adamは深層学習のオプティマイザーの一つで、以下の式で計算されます。

$$
m_t = \beta_1m_{t-1} + (1-\beta_1)g_t
$$

$$
v_t = \beta_2v_{t-1} + (1-\beta_2)g_t^2
$$

$$
\hat{m_t} = \frac{m_t}{1-\beta_1^t}
$$

$$
\hat{v_t} = \frac{v_t}{1-\beta_2^t}
$$

$$
\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v_t}}+\epsilon}\hat{m_t}
$$

- $$m_t$$ は1次モーメント
- $$v_t$$ は2次モーメント
- $$\beta_1$$ は1次モーメントの指数減衰率
- $$\beta_2$$ は2次モーメントの指数減衰率
- $$\hat{m_t}$$ は1次モーメントのバイアス補正
- $$\hat{v_t}$$ は2次モーメントのバイアス補正
- $$\theta_t$$ はt時点のパラメータ
- $$\alpha$$ は学習率
- $$\epsilon$$ は数値安定性のための定数

- [【決定版】スーパーわかりやすい最適化アルゴリズム -損失関数からAdamとニュートン法- - Qiita](https://qiita.com/omiita/items/1735c1d048fe5f611f80#7-adam)
- [サンプルコード](https://github.com/oreilly-japan/deep-learning-from-scratch-2/blob/master/common/optimizer.py#L101)

# 初期値

## Xavierの初期値

Xavierの初期値は、ニューラルネットワークの重みを適切に初期化する手法のひとつです。
Xavierの初期値を用いることで、勾配消失や爆発を防ぎ、学習を安定化させることができます。
Xavierの初期値は、前の層のノード数をn、次の層のノード数をmとすると、以下のように計算されます。

$$
W \sim N(0, \frac{1}{n})
$$

ここで、 $$N(0, σ^2)$$ は平均0、分散 $$σ^2$$ の正規分布を表します。
前後のノードがある場合は、それぞれのノード数を $$n_1$$ 、 $$n_2$$ とすると、

$$
W \sim N(0, \frac{2}{n_1 + n_2})
$$

## Heの初期値

Heの初期値は、Xavierの初期値の改良版で、ReLUなどの活性化関数を用いる場合に適した初期値です。
Heの初期値を用いることで、勾配消失や爆発を防ぎ、より高速な学習が可能になります。
Heの初期値は、前の層のノード数をnとすると、以下のように計算されます。

$$
W \sim N(0, \frac{2}{n})
$$

Xavierの初期値とは異なり、Heの初期値では分散が2/nとなっています。

## バッチ正規化

バッチ正規化は、ニューラルネットワークの中間層の出力を正規化することで、学習を高速化し、精度を向上させる手法です。バッチサイズごとに平均と分散を計算し、それを用いて入力を正規化することで、学習の収束を早めることができます。
バッチ正規化の詳細については、[こちらの記事](https://deepage.net/deep_learning/2016/10/26/batch_normalization.html)をご覧ください。

## レイヤー正規化

レイヤー正規化は、バッチ正規化のように **中間層の出力** を正規化する手法ですが、バッチ正規化と異なり、バッチ内ではなく層内で正規化を行います。そのため、バッチサイズに依存しないモデルの学習が可能になります。
レイヤー正規化の詳細については、[こちらの論文](https://arxiv.org/abs/1607.06450)をご覧ください。

## グループ正規化

グループ正規化は、 **レイヤー正規化の一種であり、層内の特徴マップをグループ単位で正規化する** 手法です。
グループ正規化を用いることで、層内での正規化がうまくいかない場合でも、グループ単位で正規化することで学習を安定化させることができます。
グループ正規化の詳細については、[こちらの論文](https://arxiv.org/abs/1803.08494)をご覧ください。

## インスタンス正規化

インスタンス正規化は、バッチ正規化やレイヤー正規化のように、中間層の出力を正規化する手法ですが、 **バッチサイズや層内のグループごとではなく、各特徴マップごと** に正規化を行います。
そのため、畳み込み層の特徴マップに対しても適用可能であり、画像の局所的な特徴を捉えることができます。
インスタンス正規化の詳細については、[こちらの論文](https://arxiv.org/abs/1607.08022)をご覧ください。